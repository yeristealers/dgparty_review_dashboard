import streamlit as st
import pandas as pd
from shareplum import Office365
from shareplum import Site
from shareplum.site import Version
from io import StringIO 

@st.cache_data
def get_authcookie():
    authcookie = Office365('https://wholesumbrands.sharepoint.com', username='yeri@wholesumbrands.com', password='2023June12/').GetCookies()
    return authcookie

@st.cache_data
def get_file_from_sharepoint(file_name):
    authcookie = get_authcookie()
    site = Site('https://wholesumbrands.sharepoint.com/sites/data_auto', version=Version.v365, authcookie=authcookie)
    folder = site.Folder('Shared Documents/Sales/DS Team/Raw/Archive')

    try:
        file_content = folder.get_file(file_name)
        return pd.read_csv(StringIO(file_content.decode('utf-8')), low_memory=False)
    except Exception as e:
        st.error(f"Error loading file {file_name}: {e}")
        return None

naver_df = get_file_from_sharepoint('naver_all_reviews.csv')
if naver_df is not None:
    naver_df = naver_df.drop(columns=['brand_e', 'review_id', 'date'])
    naver_df['product_code'] = naver_df['product_code'].astype(str)
    naver_df['review_date'] = pd.to_datetime(naver_df['review_date']).dt.strftime('%Y-%m-%d')
    naver_df = naver_df.rename(columns={
        'brand_k': 'ë¸Œëœë“œ',
        'channel': 'ì±„ë„',
        'product_code': 'ìƒí’ˆì½”ë“œ',
        'review_date': 'ë¦¬ë·°ë‚ ì§œ',
        'user': 'ë¦¬ë·°ì•„ì´ë””',
        'product_name': 'ìƒí’ˆëª…',
        'product_option': 'ì˜µì…˜ëª…',
        'rating': 'ì ìˆ˜',
        'review_type': 'ë¦¬ë·°íƒ€ì…',
        'repurchase': 'ì¬êµ¬ë§¤',
        'review_details': 'ìƒí’ˆí‰'
    })

#coupang_df = get_file_from_sharepoint(sales_folder, 'coupang_all_reviews.csv')
#if coupang_df is not None:
#    coupang_df = coupang_df.drop(columns=['brand_e', 'review_id', 'date'])
#    coupang_df['product_id'] = coupang_df['product_id'].astype(str)
#    coupang_df = coupang_df.rename(columns={
#        'brand_k': 'ë¸Œëœë“œ',
#        'channel': 'ì±„ë„',
#        'seller': 'íŒë§¤ì',
#        'product_id': 'ìƒí’ˆì½”ë“œ',
#        'review_date': 'ë¦¬ë·°ë‚ ì§œ',
#        'user': 'ë¦¬ë·°ì•„ì´ë””',
#        'review_title': 'ë¦¬ë·°ì œëª©',
#        'product_details': 'ìƒí’ˆëª…',
#        'product_option': 'ì˜µì…˜ëª…',
#        'rating': 'ì ìˆ˜',
#        'review_type': 'ë¦¬ë·°íƒ€ì…',
#        'repurchase': 'ì¬êµ¬ë§¤',
#        'review_details': 'ìƒí’ˆí‰'
#    })

st.title("ğŸ”ë“ê·¼íŒŒí‹° ë¦¬ë·° ëŒ€ì‹œë³´ë“œğŸ”")
st.write("")

st.subheader('')
#st.dataframe('')

tabs = st.tabs(["ë„¤ì´ë²„ ë¦¬ë·°"]) #, "ì¿ íŒ¡ ë¦¬ë·°"
with tabs[0]:
    st.subheader('ë„¤ì´ë²„ ë¦¬ë·° ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°')
    naver_brand_filter = st.selectbox("ë¸Œëœë“œ", options=naver_df["ë¸Œëœë“œ"].unique())
    naver_date_filter = st.date_input("ë¦¬ë·° ë‚ ì§œ", [])

    filtered_naver_df = naver_df.copy()
    if naver_brand_filter:
        filtered_naver_df = filtered_naver_df[filtered_naver_df["ë¸Œëœë“œ"] == naver_brand_filter]
    if naver_date_filter:
        filtered_naver_df = filtered_naver_df[
            pd.to_datetime(filtered_naver_df["ë¦¬ë·°ë‚ ì§œ"], errors='coerce').dt.date == pd.to_datetime(naver_date_filter).date()
        ]
        #filtered_naver_df = filtered_naver_df[pd.to_datetime(filtered_naver_df["ë¦¬ë·°ë‚ ì§œ"]).isin(pd.to_datetime(naver_date_filter))]

    # ë„¤ì´ë²„ ë¦¬ë·° ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    naver_csv = filtered_naver_df.to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label=f"ë„¤ì´ë²„ {naver_brand_filter} ë¦¬ë·° ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
        data=naver_csv,
        file_name=f'naver_{naver_brand_filter}_reviews.csv',
        mime='text/csv'
    )
    st.subheader('ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ì¤„)')
    st.dataframe(filtered_naver_df.head())
    
#with tabs[1]:
#    st.subheader('ì¿ íŒ¡ ë¦¬ë·° ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°')
#    coupang_brand_filter = st.selectbox("ë¸Œëœë“œ", options=coupang_df["ë¸Œëœë“œ"].unique())
#    coupang_date_filter = st.date_input("ë¦¬ë·°ë‚ ì§œ", [])

    # í•„í„° ì ìš©
#    filtered_coupang_df = coupang_df.copy()
#    if coupang_brand_filter:
#        filtered_coupang_df = filtered_coupang_df[filtered_coupang_df["ë¸Œëœë“œ"] == coupang_brand_filter]
#    if coupang_date_filter:
#        filtered_coupang_df = filtered_coupang_df[pd.to_datetime(filtered_coupang_df["ë¦¬ë·°ë‚ ì§œ"]).isin(pd.to_datetime(coupang_date_filter))]

    # í•„í„°ë§ëœ ì¿ íŒ¡ ë°ì´í„° ì¶œë ¥
#    st.dataframe(filtered_coupang_df)

# ë¸Œëœë“œ, ì±„ë„, ë‚ ì§œ í•„í„° ì˜µì…˜
#st.sidebar.header("í•„í„° ì˜µì…˜")
#brand_filter = st.sidebar.multiselect("ë¸Œëœë“œ ì„ íƒ", options=concat_df["ë¸Œëœë“œ"].unique())
#channel_filter = st.sidebar.multiselect("ì±„ë„ ì„ íƒ", options=concat_df["ì±„ë„"].unique())
#date_filter = st.sidebar.date_input("review_date", [])

# í•„í„° ì ìš©
#filtered_df = concat_df.copy()
#if brand_filter:
#    filtered_df = filtered_df[filtered_df["ë¸Œëœë“œ"].isin(brand_filter)]
#if channel_filter:
#    filtered_df = filtered_df[filtered_df["ì±„ë„"].isin(channel_filter)]

#if date_filter:
#    filtered_df = filtered_df[pd.to_datetime(filtered_df["ë¦¬ë·°ë‚ ì§œ"]).isin(pd.to_datetime(date_filter))]

# í•„í„°ë§ëœ ë°ì´í„° ì¶œë ¥
#st.subheader('í•„í„°ë§ëœ ë°ì´í„°')

#st.subheader('ë¯¸ë¦¬ë³´ê¸° ë°ì´í„°')
#st.dataframe(coupang_df.head())
